## The Thinking of Man: Human Vs. A.I.

### **What is Human?**  
Humans are unique, with one trait standing out the most: our reasoning ability. 
The [earth is approximately 4.54 billion years old](https://www.nationalgeographic.org/topics/resource-library-age-earth/?q=&page=1&per_page=25&msclkid=d77c6f45cef911ec8b681f2ff17bc6bc), but the modern human has only been around for just [the last 200,000 years](https://www.universetoday.com/38125/how-long-have-humans-been-on-earth/?msclkid=58e204b4cefa11eca7cf561d5c33f5d9), which is quite insignificant in duration. Nevertheless, we’ve evolved to be the technologically advanced species, that we are today, in that span.
What’s so unique about us? Let’s find out...

<a href="https://www.researchgate.net/figure/Biological-Neuron-versus-Artificial-Neural-Network_fig4_325870973"><img src="https://www.researchgate.net/profile/Brian-Mwandau/publication/325870973/figure/fig4/AS:639531594297345@1529487622181/Biological-Neuron-versus-Artificial-Neural-Network.png" alt="1: Biological Neuron versus Artificial Neural Network"/>[source](https://www.researchgate.net/figure/Biological-Neuron-versus-Artificial-Neural-Network_fig4_325870973 )</a>

### **Depth of Consciousness**  
Neuroscience is a [multidisciplinary](https://books.google.com.ng/books?id=xfSVcBL7CSMC&q=neuroscience+multidisciplinary&pg=PA59&redir_esc=y#v=snippet&q=neuroscience%20multidisciplinary%20subject&f=false) field that combines physiology, anatomy, molecular biology, developmental biology, cytology, physics, computer science, chemistry and mathematical modeling to understand the fundamental and emergent properties of neurons, glia and neural circuits[.](https://en.wikipedia.org/wiki/Neuroscience)  

It is an ever evolving field. The more researchers get to discover, the more their [conviction on the complexity of the human neurological system](https://www.jneurosci.org/content/40/1/101?msclkid=bc3a82a2cefb11ec9964d5767c3a7362#ref-4), leading to [varied opinions from experts](https://www.jneurosci.org/content/40/1/101?msclkid=bc3a82a2cefb11ec9964d5767c3a7362) on its vastness.  
Let's try to understand the uniqueness of the brain. For the sake of this write-up, 5 simple comparisons would made with computing devices:  
  
- The brain is made up of primary functional units, which are cells called neurons along with their supporting tissue, this can be compared to the circuits of a CPU and its supporting hardware.

- The brain is a power house of complex activities: despite constituting just 2% of the body's weight, the brain consumes roughly [20% of the total oxygen absorbed by the body](https://www.spinalcord.com/blog/what-happens-after-a-lack-of-oxygen-to-the-brain), when we are at rest, and more so in a state of high metabolic need. The computer's CPU and GPU usually require the [most power for its operation.](https://superuser.com/questions/93874/whats-the-component-that-consumes-most-power-in-a-computer)

- Like computer circuits that are operated in binary (1/0), neurons are also thought of to be binary in their operation; they are either "firing" or not. And yes, just like in the computer, [electrical signals are also involved in the transmission of information in the brain.](https://jonlieffmd.com/blog/brain-electricity-and-the-mind#:~:text=It%20is%20popularly%20thought%20that%20the%20major%20electricity,the%20delivery%20of%20a%20neurotransmitter%20to%20another%20neuron), albeit via a [different mechanism.](https://www.scienceabc.com/humans/electricity-generated-neurons-brain.html)

- [Efficiency of our cerebral functions](https://nautil.us/why-is-the-human-brain-so-efficient-7216/), can be attributed usually to the parallel relay of information, which ensures that groups of neurons involved in similar functions receive and transmit electrical impulses **simultaneously**, as specialized sub-units within the brain, somewhat similar to the functional compartmental nature of cores in a processor.

- In deep learning (a specialised subset of Artificial Intelligence), an artificial neural *node* mimics the biological neuron while a *layer* of nodes mimics the [neurological sub-units](https://psychologydictionary.org/brain-nucleus/?msclkid=bd382b00ceef11ecb66b6d0ffe490589) 

<!--

|  |  |
|:--|:--|
[<img  height = "50" width = "50" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1652149675831/FdYqEXSEd.jpg" > source](https://techwiser.com/how-many-cores-does-my-cpu-have/)
[<img  height = "50" width = "50" src="https://cdn.hashnode.com/res/hashnode/image/upload/v1652149959276/fgJJe-v2h.jpg" > source](https://www.offset.com/photos/light-micrograph-of-a-transverse-section-through-the-sciatic-nerve-58193)

-->





> The goal of deep learning so far, has been to [mimic the human brain](https://www.ibm.com/cloud/learn/deep-learning) in terms of its structure and function, in order to help discern patterns in data. It's a technique that hopes to make outstanding predictions from data by studying data as the human mind would.  
 

| [<center><bold>Autonomous Vehicles: How Computers see</bold></center>](https://gizmodo.com/engineers-are-teaching-your-smartphone-to-think-like-an-1749040590)|
|:--|
|[![Autonomous Vehicle](https://i.kinja-img.com/gawker-media/image/upload/s--GWnahPtG--/c_fill,fl_progressive,g_center,h_450,q_80,w_800/zoeuwi8cmvlm0m3qyy8t.gif)](https://www.youtube.com/watch?v=MxximR-1ln4&feature=emb_imp_woyt)|


<br/> 
When you try to think about deep learning, think about it in terms of functionalities you've seen on computing devices, that **seem** to perform at human-like intelligence.  
Few examples of such are:
- Image Augmentation - [Demo](https://huggingface.co/spaces/akhaliq/GFPGAN) 
- [Face recognition](https://machinelearningmastery.com/introduction-to-deep-learning-for-face-recognition/)
- [Speech Recognition](https://deepgram.com/blog/deep-learning-speech-recognition/)
- Speech Augmentation - [Demo](https://coqui.ai/demo)
- [Digital assistants](https://9to5mac.com/2017/08/23/evolution-siri-machine-learning-journal/)
- [Self-driving cars](https://blogs.nvidia.com/blog/2019/04/30/drive-labs-path-perception/?ncid=so-you-t7-84204)
- Image-to-Text technology (i.e. [Google Lens](https://lens.google/))
- [Text-to-Image technology (Generating visual interpretations of written sentences)](https://openai.com/blog/dall-e/)([Demo](https://www.youtube.com/redirect?event=video_description&redir_token=QUFFLUhqbjRrTnphcTVReXRvbDdIZ2pXYU1Jc3pnVXpoQXxBQ3Jtc0tsNWtJVEQ4OWdWcXB1a0lLdTc3b2t2NFJKTHlNLWJWMHFXYmRScGlwOEtQWnVjUTlrR0ZwLWFxTlJ2aWs2U2prTUJZVlFkeUg1aG94cVAwUS13UUk1MVZpVndvbFEyX3Z2ZGo2a3JCSDZ6eFc2aUFVYw&q=https%3A%2F%2Fbit.ly%2F2WRbDRf&v=YKUz2yDPFCE))
- [Drug Discovery](https://www.frontiersin.org/articles/10.3389/fmicb.2021.739684/full)  
- Extra Demos: [Microsoft](https://aidemos.microsoft.com/), [Nvidia](https://www.nvidia.com/en-us/research/ai-demos/), [Expo1](https://medium.com/analytics-vidhya/10-ai-experiments-to-try-online-today-6e913777a02b), [Expo2](https://imerit.net/blog/15-crazy-ai-experiments-to-try-online-today-all-una/)  
  
The ideas and methods, implemented in deep learning [aren't exactly new.](https://towardsdatascience.com/the-deep-history-of-deep-learning-3bebeb810fb2#:~:text=%20The%20Evolution%20of%20Deep%20Learning%20%201,approaches%20in%20performance%20and%20is%20widely...%20More%20?msclkid=78675c7dcef511ecaedfa6bc69dd1758) Humans have simply researched how the human brain learned to understand things: by making credible associations between information received and subsequent outcomes gotten. We've simply been trying to mimic this functionality, artificially.
  
Building systems in place for such predictive endeavours had always been an ongoing challenge, but we didn't even have enough digital data to learn from. Then came the [exponential growth of technology](https://cp.ventures/the-exponential-growth-of-technology/) especially in this 21st century, which has led to a gigantic and ever expanding volume of data, and subsequently, done good to avail the much needed high performance hardwares, such as high performing GPUs, TPUs, CPUs, RAMs, [etc.](https://towardsdatascience.com/another-deep-learning-hardware-guide-73a4c35d3e86) to handle more tasking objectives, at a better precision. As a result, we've had the [resurgence of deep learning](https://www.amacad.org/sites/default/files/publication/downloads/Daedalus_Sp22_04_Dean.pdf).  

<br/>

Invariably this development, has increased the frequency of debates on the general outlook of Artificial Intelligence (A.I.), as well as the idea of Artificial Intelligence taking over human jobs, with a notable example being healthcare.
  


| [<center><bold>AI Segmentation of a Lung Tumour</bold></center>](https://www.rsipvision.com/lung-tumor-segmentation/) |
|:--|
|[![Lung-tumors-segmentation.gif](https://cdn.hashnode.com/res/hashnode/image/upload/v1653081298719/LlpQWtSUq.gif align="center")](https://www.rsipvision.com/lung-tumor-segmentation/)|





Medical experts do not see a take over happening, but rather, more of [A.I. augmenting work in healthcare](https://youtu.be/PZQMyj-9z-w) as it is a field saturated with complex protocols and procedures, and if such a take over is ever to be, then [it’s likely years away](https://www.forbes.com/sites/forbestechcouncil/2019/03/15/ai-will-not-replace-doctors-but-it-may-drastically-change-their-jobs/?sh=2faeaa53636a). Although, as human beings we've learnt to never underestimate the growth and trajectory of human technology.  
 
  
Right now, studies in [Diagnostic Radiology](https://arxiv.org/abs/2004.10507), [Cancer Research](https://arxiv.org/abs/1606.05718) and [Dentistry](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6502856/) are being undertaken by top medical institutes with funding supplied by top organizations (i.e. Google, Meta, Nividia, etc.), with Centres of learning being established and dedicated, to the study of the applications of Artificial Intelligence in healthcare as well as the [ethical issues](https://plato.stanford.edu/entries/ethics-ai/) that might spawn.
  

|  [<center><bold>Pneumonia Detection Using Retina Net</bold></center>](https://www.springml.com/blog/pneumonia-detection-using-retina-net/)|  |
|--:|:--|
|[![normal_xray.png](https://cdn.hashnode.com/res/hashnode/image/upload/v1652937757337/8N303ex0e.png align="left")](https://www.springml.com/wp-content/uploads/2019/04/normal_xray.png) |[![XRAY_IMG_SEG.png](https://cdn.hashnode.com/res/hashnode/image/upload/v1652933847801/gBgev0KEE.png align="left")](https://www.springml.com/wp-content/uploads/2019/04/lung_opacity.png)|


  
  
[Healthcare is peculiar.](https://www.forbes.com/sites/adigaskell/2019/01/18/doctors-are-confident-that-ai-wont-replace-them/?sh=2e3f6f987404) Technical skills aside, empathy, which is a key concept around human care, [has not been replaced by A.I.](https://www.youtube.com/watch?v=PZQMyj-9z-w&t=266s) and so far as human beings are still the patients, [showing empathy would go a long way in acceptance of care](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7151200/#:~:text=Understanding%20based%20on%20empathy%20is%20critical%20to%20the,come%20closer%2C%20enjoying%20mutual%20benefits%20%5B%2012%20%5D.), and handling such objective and subjective outcomes, is what makes every patient interaction unique.
One must admit though, that simple repetitive tasks can and would be easily taken over by A.I., as humans cannot under any **natural** circumstance rival their computing power and speed, which is why popular debates [should never have included a Tech. Vs. Human premise.](https://medicalfuturist.com/5-reasons-artificial-intelligence-wont-replace-physicians/)
 
It would always help, to imagine what healthcare teams would be capable of, if their creativity, associative reasoning, complex pattern recognition, and problem-solving skills, were combined with the tremendous computing power, extraordinary speed, and processing efficiency available to computing devices. We'd be simply augmenting our intelligence as humans, and such augmentations are needed to [broaden access to healthcare](https://medium.com/retina-ai-health-inc/artificial-intelligence-and-telemedicine-in-a-world-of-value-based-healthcare-a-deep-dive-311073d33ebf), especially in regions of the world with grossly [diminished medical man-power.](https://borgenproject.org/ai-in-african-healthcare-revolutionizing-the-industry/#:~:text=Future%20of%20AI%20in%20African%20Health%20Care%20Overall%2C,communicate%20with%20patients%20and%20provide%20more%20accurate%20diagnoses.)
> The Average human is [ahead of A.I. systems](https://thenextweb.com/news/why-the-smartest-ai-is-still-dumber-than-a-toddler-and-how-we-can-fix-that) in predictive analysis, as we have a key sense of association,. The advantage with computers is that, with every predictive task they are successfully trained to solve, they would easily outperform any human just by sheer computing speed. [Your brain is 10 million times slower than a computer.](https://nautil.us/why-is-the-human-brain-so-efficient-7216/)

### **Conclusion**

The race for the COVID-19 vaccine showed clearly, the value of state-of-the-art research. The potentials in placing oneself at the frontline of innovation, cannot be overstated, and humans who think further and do further, would achieve farther as our global society evolves.  
  
A.I. is here to stay, despite the general outlook of its potential not being fully known, I strongly believe it is going to be a driving force for much greater global development, in coming years. 

<br/><br/>

### **Glossary**  
- **Computer vision**:  *is a field of artificial intelligence that trains computers to interpret and understand the visual world*  
  
- **Computing**: *the use or operation of computers.*
  
- **CPU (Central Processing Unit)**: *is the electronic circuitry that is involved in executing the  instructions of a computer program*  
  
- **Deep Learning** : *a type of machine learning based on artificial neural networks in which multiple layers of processing are used to extract progressively higher level features from data.*  
   
- **Diagnostic radiology** : *refers to the field of medicine that uses non-invasive imaging scans to diagnose a patient.*  
  
- **GPU (Graphics Processing Unit)**:  *it’s the part of the PC responsible for the on-screen images you see.*
  
- **Neurological**: *relating to the anatomy, functions, and organic component of nerves and the nervous system.*  
  
- **Neuroscience**: *describes the multi-disciplinary scientific study of the nervous system*  

- **Node**: *a computational unit in a neural network which mimics a biologic neuron, by handling information through computational logic, giving a desired output*  
  
- **State-of-the-art**:  *very modern and using the most recent ideas and methods*  
  
- **Specialty**: *a pursuit, area of study, or skill to which someone has devoted much time and effort and in which they are expert.*  
  
  
### Let's Connect
| | | | | | | 
|:--|:--|:--|:--|:--|:--|
|[Project Portfolio](https://invest41.github.io/AlaoDavid.github.io/)|[GitHub](https://github.com/invest41)| [Twitter](https://mobile.twitter.com/Wilder_Maxim)| [Kaggle](https://www.kaggle.com/welcomehere)| [Linkedin](https://www.linkedin.com/in/david-alao-72362113b/)|[Tableau](https://public.tableau.com/app/profile/alao.david)|